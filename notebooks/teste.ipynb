{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f15c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "ROOT = rootutils.setup_root(\n",
    "    search_from=__file__ if \"__file__\" in globals() else \".\",\n",
    "    indicator=\".project-root\",\n",
    "    pythonpath=True\n",
    ")\n",
    "\n",
    "from hydra_utils.utils import instantiate_tree\n",
    "\n",
    "os.chdir(ROOT)\n",
    "\n",
    "config_path = Path(\"hydra_utils\") / \"rag_system.yaml\"\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "cfg_yaml = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9f6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra_utils.utils import instantiate_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197c63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dracb\\anaconda3\\envs\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vector_db': <rag_system.VectorDB.db.VectorDB object at 0x000002028E1F89D0>, 'retrieval_system': <rag_system.retrieval.re.RetrievalSystem object at 0x00000202B7450EB0>, 'generator': <main.generator.OllamaGenerator object at 0x00000202B7450F40>, 'semantical_model': SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False, 'architecture': 'MPNetModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "), 'chunker': <rag_system.chunking.json_splitter.RecursivePDFChunker object at 0x00000202DF94E6E0>, 'rag_pipeline': <rag_system.pipeline.RagSystemPipeline object at 0x00000202E178E770>}\n"
     ]
    }
   ],
   "source": [
    "instances = instantiate_tree(cfg_yaml)\n",
    "\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8440c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'RAG significa \"Retrieval-Augmented Generator\" (gerador aprimorado com recuperação) e refere-se a uma técnica utilizada na inteligência artificial (IA) para combinar as vantagens de dois modelos separados de processamento de linguagem natural: os geradores de texto e os pesquisadores.\\n\\nOs geradores de texto são projetados para criar textos novos, baseados em um modelo estatístico aprendido com dados de treinamento. Por outro lado, os pesquisadores de texto são projetados para recuperar informação específica do conhecimento armazenada em uma base de dados.\\n\\nEm RAG, o gerador usa a saída de um pesquisador como input para criar textos mais complexos ou com precisão maior. O modelo de pesquisa é treinado para recuperar informações relevantes sobre um determinado tópico e o modelo de geração usa essas informações para criar respostas mais completas.\\n\\nEssa abordagem combina a capacidade do gerador em criar textos criativos com a precisão do pesquisador ao recuperar informações específicas, resultando na criação de respostas mais eficazes e precisas.', 'retrievals': {'documents': [], 'query': 'Explique o que é RAG em IA'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/ask_ollama3_with_rag_endpoint\"\n",
    "prompt = {\"prompt\": \"Explique o que é RAG em IA\"}\n",
    "\n",
    "response = requests.post(url, json=prompt)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09e2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG (Retriever-Augmented Generator) é um modelo de linguagem desenvolvido pela Meta, baseado em uma combinação de dois modelos de processamento de linguagem. O primeiro componente é um \"retrôve\" ou 'buscador' que busca a informação mais relevante no texto, e o segundo componente é um gerador que utiliza as informações buscadas para gerar a resposta final ao usuário.\n",
      "RAG é frequentemente comparado a outros modelos de linguagem como T5 e PaLM, pois todos eles buscam melhorar a qualidade das respostas geradas.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/ask_ollama3_stream\"\n",
    "prompt = {\"prompt\": \"Explique o que é RAG em IA\"}\n",
    "\n",
    "response = requests.post(url, json=prompt)\n",
    "for chunk in response.iter_lines():\n",
    "    if chunk:\n",
    "        print(chunk.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd15b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
